---
publish: true
review-frequency: normal
link:
- '[[complexity]]'
- '[[failure]]'
- '[[System]]'
tags:
- documentation
---

# How Complex Systems Fail
1. Complex systems are intrinsically hazardous systems.
    - In defense against hazardous systems creates a very complex system.
2. Complex systems are heavily and successfully defended against failure.
    - Complex layers of defense divert operations away from accidents.
3. Catastrophe requires multiple failures - single point failures are not enough.
4. Complex systems contain changing mixtures of failures latent within them.
    - Multiple flaws always present, might be economically costly to eradicate all flaws.
    - Failures change constantly due to technology change.
5. Complex systems run in degraded mode.
6. Catastrophe is always just around the corner.
7. Post-accident attribution to a "root cause" is fundamentally wrong.
8. Hindsight biases post-accident assessments of human performance.
    - Knowing the facts leading up to the accident post fact, does not mean it should be recognized in the first place.
9. Human operators have dual roles: as producers & as defenders against failure.
10. All practitioner actions are gambles.
11. Actions at the sharp end resolve all ambiguity.
12. Human practitioners are the adaptable element of complex systems.
13. Human expertise in complex systems is constantly changing
14. Change introduces new forms of failure.
15. Views of 'cause' limit the effectiveness of defenses against future events.
16. Safety is a characteristic of systems and not of their components
17. People continuously create safety.
18. Failure free operations require experience with failure.

---
# References
- [How complex system Fail](https://how.complexsystems.fail/)